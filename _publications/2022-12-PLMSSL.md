---
title: "Precise Location Matching Improves Dense Contrastive Learning in Digital Pathology"
collection: publications
category: conferences
permalink: /publication/2022-12-PLMSSL
excerpt: 'We propose a precise location-based matching mechanism for dense contrastive learning that utilizes overlapping information between geometric transformations to accurately match dense features in histopathology images.'
date: 2022-12-23
venue: 'International Conference on Information Processing in Medical Imaging (IPMI)'
paperurl: https://arxiv.org/abs/2212.12105
citation: '<strong>Jingwei Zhang</strong>*, Saarthak Kapse*, Ke Ma, Prateek Prasanna, Maria Vakalopoulou, Joel Saltz, Dimitris Samaras, &quot;Precise Location Matching Improves Dense Contrastive Learning in Digital Pathology&quot;, <i>International Conference on Information Processing in Medical Imaging (IPMI)</i>, 2023.'
figure: /files/images/publications/2022-12-PLMSSL.png
---

**Abstract**.      Dense prediction tasks such as segmentation and detection of pathological entities hold crucial clinical value in computational pathology workflows. However, obtaining dense annotations on large cohorts is usually tedious and expensive. Contrastive learning (CL) is thus often employed to leverage large volumes of unlabeled data to pre-train the backbone network. To boost CL for dense prediction, some studies have proposed variations of dense matching objectives in pre-training. However, our analysis shows that employing existing dense matching strategies on histopathology images enforces invariance among incorrect pairs of dense features and, thus, is imprecise. To address this, we propose a precise location-based matching mechanism that utilizes the overlapping information between geometric transformations to precisely match regions in two augmentations. Extensive experiments on two pretraining datasets (TCGA-BRCA, NCT-CRC-HE) and three downstream datasets (GlaS, CRAG, BCSS) highlight the superiority of our method in semantic and instance segmentation tasks. Our method outperforms previous dense matching methods by up to 7.2% in average precision for detection and 5.6% in average precision for instance segmentation tasks. Additionally, by using our matching mechanism in the three popular contrastive learning frameworks, MoCo-v2, VICRegL, and ConCL, the average precision in detection is improved by 0.7% to 5.2%, and the average precision in segmentation is improved by 0.7% to 4.0%, demonstrating generalizability.

More information are available at [IPMI](https://link.springer.com/chapter/10.1007/978-3-031-34048-2_60), [arxiv](https://arxiv.org/abs/2212.12105) and [code](https://github.com/cvlab-stonybrook/PLM_SSL).  


